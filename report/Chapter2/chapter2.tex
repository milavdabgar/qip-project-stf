% chapter2.tex

\chapter{Dataset, Metadata, and Exploratory Data Analysis}

\section{Dataset Overview}

The dataset originates from Microsoft's Malware Prediction competition on Kaggle, containing real-world Windows system telemetry for binary classification: predicting malware presence (\texttt{HasDetections = 1}) or absence (\texttt{HasDetections = 0}).

\section{Dataset Metadata}

\begin{table}[h]
\centering
\caption{Dataset Metadata}
\label{tab:dataset_metadata}
\begin{tabular}{|l|r|}
\hline
\textbf{Property} & \textbf{Value} \\
\hline
Total Samples & 100,000 \\
Train/Val Split & 80,000 / 20,000 (80/20\%) \\
Features (Numerical/Categorical) & 75 (47/28) \\
Target Classes & Binary (50.52\% malware, 49.48\% clean) \\
Missing Values & 1-30\% in multiple features \\
\hline
\end{tabular}
\end{table}

\subsection{Feature Categories}

Features span hardware (12), OS (8), security software (6), system settings (15), installation/update (10), and behavioral indicators (24). The 47 numerical features include continuous (RAM, timestamps) and discrete (version numbers, counts) with highly variable ranges. The 28 categorical features have 2-1,000+ unique values requiring numerical encoding.

\section{Exploratory Data Analysis}

\subsection{Key EDA Findings}

\textbf{Weak Correlations}: Maximum feature-target correlation is only 0.118, indicating no single feature provides strong predictive power. This necessitates complex interaction modeling and establishes a performance ceiling around 63\%.

\textbf{Balanced Classes}: Near-perfect 50.52\% vs. 49.48\% split eliminates resampling needs and validates accuracy as primary metric.

\subsection{Missing Values and Distributions}

Missing rates vary: 15-30\% (security software), 5-20\% (hardware), 1-10\% (settings). Imputation strategy: mean for numerical, mode for categorical.

Numerical features show heavy-tailed, multimodal distributions requiring scaling. Categorical features have high cardinality (up to 1,000+ categories), necessitating label encoding. Feature-feature correlations are weak (max 0.42), indicating independence and justifying retention of all 75 features.

\section{Modeling Implications}

Weak correlations (max 0.118) and high dimensionality (75 features) favor tree-based methods over distance-based approaches. Heterogeneous data types (47 numerical, 28 categorical) advantage ML models with native mixed-type handling. Balanced classes simplify evaluation. These characteristics establish an expected performance ceiling around 63\% and informed our systematic ML vs. DL comparison detailed in Chapter 3.