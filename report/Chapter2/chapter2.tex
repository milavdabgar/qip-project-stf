% chapter2.tex

\chapter{Dataset, Metadata, and Exploratory Data Analysis}

\section{Dataset Overview}

The dataset originates from Microsoft's Malware Prediction competition on Kaggle~\cite{kaggle_stf_competition}, containing real-world Windows system telemetry for binary classification: predicting malware presence (\texttt{HasDetections = 1}) or absence (\texttt{HasDetections = 0}).

\section{Dataset Metadata}

\begin{table}[h]
\centering
\caption{Dataset Metadata}
\label{tab:dataset_metadata}
\begin{tabular}{|l|r|}
\hline
\textbf{Property} & \textbf{Value} \\
\hline
Total Samples & 100,000 \\
Train/Val Split & 80,000 / 20,000 (80/20\%) \\
Features (Numerical/Categorical) & 75 (47/28) \\
Target Classes & Binary (50.52\% malware, 49.48\% clean) \\
Missing Values & 1-30\% in multiple features \\
\hline
\end{tabular}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{../beamer/figures/target_distribution.png}
\caption{Target Class Distribution: Near-perfect 50.52\% malware vs. 49.48\% clean split eliminates need for resampling strategies.}
\label{fig:target_distribution}
\end{figure}

\subsection{Feature Categories}

Features span hardware (12), OS (8), security software (6), system settings (15), installation/update (10), and behavioral indicators (24). The 47 numerical features include continuous (RAM, timestamps) and discrete (version numbers, counts) with highly variable ranges. The 28 categorical features have 2-1,000+ unique values requiring numerical encoding.

\section{Exploratory Data Analysis}

\subsection{Key EDA Findings}

\textbf{Weak Correlations}: Maximum feature-target correlation is only 0.118, indicating no single feature provides strong predictive power. This necessitates complex interaction modeling and establishes a performance ceiling around 63\%.

\textbf{Balanced Classes}: Near-perfect 50.52\% vs. 49.48\% split eliminates resampling needs and validates accuracy as primary metric.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{../beamer/figures/correlation_heatmap.png}
\caption{Feature Correlation Heatmap: Maximum correlation with target (HasDetections) is only 0.118, demonstrating weak linear relationships and necessitating ensemble methods.}
\label{fig:correlation_heatmap}
\end{figure}

\subsection{Missing Values and Distributions}

Missing rates vary: 15-30\% (security software), 5-20\% (hardware), 1-10\% (settings). Imputation strategy: mean for numerical, mode for categorical.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{../beamer/figures/missing_values.png}
\caption{Missing Values Analysis: Up to 30\% missing data in security software features, requiring careful imputation strategies.}
\label{fig:missing_values}
\end{figure}

Numerical features show heavy-tailed, multimodal distributions requiring scaling. Categorical features have high cardinality (up to 1,000+ categories), necessitating label encoding. Feature-feature correlations are weak (max 0.42), indicating independence and justifying retention of all 75 features.

\section{Modeling Implications}

Weak correlations (max 0.118) and high dimensionality (75 features) favor tree-based methods over distance-based approaches. Heterogeneous data types (47 numerical, 28 categorical) advantage ML models with native mixed-type handling. Balanced classes simplify evaluation. These characteristics establish an expected performance ceiling around 63\% and informed our systematic ML vs. DL comparison detailed in Chapter 3.