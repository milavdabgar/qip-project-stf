% chapter1.tex 

\chapter{Introduction}

\section{Background and Motivation}

Modern organizations face over 200,000 new malware samples daily. Traditional signature-based detection systems, which rely on pattern matching against known malware databases, have become ineffective against sophisticated threats. Zero-day attacks—exploiting previously unknown vulnerabilities—circumvent signature databases entirely, creating critical security gaps.

Machine learning and deep learning offer a paradigm shift from reactive to proactive defense by analyzing behavioral patterns rather than static signatures. This project investigates which approach—traditional machine learning or modern deep learning—provides superior performance for malware detection through comprehensive experimentation using the Kaggle Microsoft Malware Prediction dataset, comparing 7 ML algorithms against 6 DL architectures.

\subsection{The ML vs. DL Debate for Tabular Data}

While deep learning has revolutionized computer vision and NLP, its effectiveness on tabular cybersecurity data remains an open question. Recent research suggests tree-based ensemble methods often outperform neural networks on structured data lacking spatial or temporal patterns. This work addresses this gap by implementing state-of-the-art models from both paradigms under identical conditions: same dataset, preprocessing, validation strategy, and metrics.

\section{Problem Statement and Research Questions}

Developing accurate malware prediction systems faces multiple challenges:

\begin{enumerate}
    \item \textbf{High Dimensionality}: 75 heterogeneous features spanning hardware, OS, security software, and behavioral indicators requiring careful preprocessing.
    
    \item \textbf{Weak Correlations}: Maximum feature-target correlation is only 0.118, necessitating complex interaction modeling.
    
    \item \textbf{Missing Data}: 1-30\% missing values, with security software attributes particularly incomplete.
    
    \item \textbf{Mixed Data Types}: 47 numerical and 28 categorical variables with cardinalities ranging from 2 to 1,000+.
    
    \item \textbf{Performance Ceiling}: Top Kaggle leaderboard reaches only 69.6\%, indicating high irreducible error.
\end{enumerate}

\subsection{Research Questions}

\begin{enumerate}
    \item How do traditional ML algorithms compare against DL architectures for tabular malware prediction?
    
    \item Does increasing neural network complexity (60K to 1.6M parameters) provide meaningful performance improvements?
    
    \item What are the practical trade-offs in training time, computational resources, deployment complexity, and interpretability?
\end{enumerate}

\section{Objectives and Contributions}

This work implements and compares 13 models (7 ML algorithms + 6 DL architectures) under controlled conditions with identical preprocessing and evaluation metrics. Key contributions include:

\begin{enumerate}
    \item \textbf{Empirical Evidence}: Demonstrates gradient boosting (LightGBM: 62.94\%) outperforms deep learning (61.79\%) by 1.15\% with 4x faster training for tabular malware data.
    
    \item \textbf{Architecture Analysis}: Increasing DL complexity from 38K to 1.6M parameters yields only 0.34\% variation, confirming dataset quality—not model sophistication—determines performance.
    
    \item \textbf{Practical Guidelines}: Establishes decision criteria favoring tree-based ensembles over DL for tabular cybersecurity data with moderate samples and weak correlations.
    
    \item \textbf{Production Deployment}: Full-stack web application at \url{https://stf.milav.in} with all trained models, interactive comparison, and live predictions.
\end{enumerate}