% System Threat Forecaster Presentation
\documentclass[aspectratio=169]{beamer}

% Theme
\usetheme{Madrid}
\usecolortheme{default}

% Packages
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,positioning}

% Title Information
\title{System Threat Forecaster}
\subtitle{AICTE QIP PG Certification Programme on\\``Deep Learning: Fundamentals and Applications''}
\author{Milav Jayeshkumar Dabgar}
\institute{%
    Government Polytechnic Palanpur\\
    Department of Electronics and Communication Engineering
}
\date{December 2025}

\begin{document}

% Title Slide
\begin{frame}
\titlepage
\end{frame}

% Outline
\begin{frame}{Outline}
\begin{columns}[t]
\column{0.5\textwidth}
\tableofcontents[sections={1-3}]

\column{0.5\textwidth}
\tableofcontents[sections={4-6}]
\end{columns}
\end{frame}

% Section 1: Project Context
\section{Project Context \& Learning Objectives}

\subsection{Problem Statement}
\begin{frame}{Problem Statement: Objectives \& Challenges}
\begin{alertblock}{Goal}
Predict malware infections and compare ML vs DL performance on tabular data
\end{alertblock}

\vspace{0.3cm}

\begin{columns}[T]
\column{0.5\textwidth}
\textbf{Key Objectives:}
\begin{enumerate}
    \item Kaggle System Threat Forecaster
    \item Implement 7 ML algorithms
    \item Build 6 DL architectures
    \item ML vs DL comparison
    \item Full-stack deployment
    \item Production web app
\end{enumerate}

\column{0.5\textwidth}
\textbf{Key Challenges:}
\begin{itemize}
    \item \textbf{Top leaderboard:} 69.6\%
    \item High dimensionality (75 features)
    \item Weak correlations (max 0.118)
    \item High irreducible error (30\%+)
    \item Missing values in critical features
    \item 100K samples, balanced classes
\end{itemize}
\end{columns}
\end{frame}

% Section 2: Data & Methodology
\section{Data \& Methodology}

\subsection{Dataset Overview}
\begin{frame}{Dataset: Kaggle - System Threat Forecaster Competition}
\begin{columns}[T]
\column{0.5\textwidth}
\textbf{Data Characteristics:}
\begin{itemize}
    \item \textbf{Size:} 100,000 samples
    \item \textbf{Features:} 75 total
    \begin{itemize}
        \item 47 numerical
        \item 28 categorical
    \end{itemize}
    \item \textbf{Target:} Binary (malware: yes/no)
    \item \textbf{Balance:} 50.52\% / 49.48\%
    \item \textbf{Split:} 80/20 train-validation (stratified)
\end{itemize}

\vspace{0.3cm}

\textbf{Critical Insight:}
\begin{alertblock}{Data Quality}
\textbf{Weak correlations} (max 0.118) + High noise = Performance ceiling ~63\%
\end{alertblock}

\column{0.5\textwidth}
\includegraphics[width=\textwidth,height=0.7\textheight,keepaspectratio]{figures/feature_correlation.png}
\end{columns}
\end{frame}

\subsection{Methodology}
\begin{frame}{Experimental Methodology \& Pipeline}
\begin{columns}[T]
\column{0.5\textwidth}
\textbf{Preprocessing Steps:}
\begin{enumerate}
    \item \textbf{Missing Values:}
    \begin{itemize}
        \item Mean imputation (numerical)
        \item Mode imputation (categorical)
    \end{itemize}
    \item \textbf{Encoding:} LabelEncoder for categorical
    \item \textbf{Scaling:} StandardScaler for numerical
    \item \textbf{Validation:} Stratified K-Fold
\end{enumerate}

\vspace{0.3cm}

\textbf{Evaluation Metrics:}
\begin{itemize}
    \item Accuracy
    \item F1 Score (primary)
    \item Precision \& Recall
    \item Confusion Matrix
\end{itemize}

\column{0.5\textwidth}
\textbf{Model Development:}
\begin{enumerate}
    \item \textbf{ML:} 7 algorithms (scikit-learn)
    \item \textbf{DL:} 6 architectures (PyTorch)
    \item \textbf{GPU:} Apple MPS optimization
    \item \textbf{Tuning:} Grid search + validation
    \item \textbf{Goal:} ML vs DL comparison
\end{enumerate}

\vspace{0.3cm}

\begin{block}{Reproducibility}
Random seed: 42 | Version control: Git | Config management
\end{block}
\end{columns}
\end{frame}

% Section 3: Model Experimentation
\section{Model Experimentation \& Learning}

\subsection{Machine Learning}
\begin{frame}{Machine Learning: 7 Algorithms Explored}
\begin{columns}[T]
\column{0.5\textwidth}
\textbf{Algorithms Implemented:}
\begin{enumerate}
    \item \textbf{LightGBM} - 62.94\% (Winner!)
    \item Random Forest - 62.09\%
    \item AdaBoost - 61.26\%
    \item Decision Tree - 60.10\%
    \item Logistic Regression - 60.07\%
    \item Naive Bayes - 55.06\%
    \item SGD Classifier - 49.46\%
\end{enumerate}

\column{0.5\textwidth}
\textbf{Key Insights:}
\begin{itemize}
    \item \textbf{Gradient boosting} best for tabular data
    \item \textbf{Hyperparameter impact:}
    \begin{itemize}
        \item Learning rate: 0.1 optimal
        \item Max depth: 5 prevents overfitting
        \item Regularization crucial
    \end{itemize}
    \item \textbf{Ensemble} methods superior
    \item \textbf{F1 score} more informative than accuracy
\end{itemize}

\begin{block}{Performance Context}
62.94\% vs Kaggle top 69.6\% = 6.7\% gap indicates high dataset noise
\end{block}
\end{columns}
\end{frame}

\begin{frame}{ML Model Performance Comparison}
\begin{center}
\includegraphics[width=0.85\textwidth]{figures/model_comparison.png}
\end{center}

\vspace{0.2cm}
\begin{block}{Key Results}
\textbf{Best ML:} LightGBM 62.94\% (F1: 0.6286) | \textbf{Best DL:} Deep MLP 61.79\% (F1: 0.6130) | \textbf{Kaggle Top:} 69.6\%
\end{block}
\end{frame}

\begin{frame}{Best ML Model: LightGBM Performance}
\begin{columns}[T]
\column{0.5\textwidth}
\textbf{Confusion Matrix:}
\includegraphics[width=\textwidth]{figures/confusion_matrix_lightgbm.png}

\column{0.5\textwidth}
\textbf{Performance Metrics:}
\begin{itemize}
    \item \textbf{Accuracy:} 62.94\%
    \item \textbf{F1 Score:} 0.6286
    \item \textbf{Precision:} 0.6299
    \item \textbf{Recall:} 0.6294
\end{itemize}

\vspace{0.3cm}

\textbf{Model Characteristics:}
\begin{itemize}
    \item Training: 80,000 samples
    \item Validation: 20,000 samples
    \item True Positives: 9,700
    \item True Negatives: 9,900
    \item False Positives: 2,100
    \item False Negatives: 2,300
\end{itemize}
\end{columns}
\end{frame}

\subsection{Deep Learning}
\begin{frame}{Deep Learning: 6 Architectures Explored}
\begin{columns}[T]
\column{0.5\textwidth}
\textbf{Implemented from Scratch:}
\begin{enumerate}
    \item \textbf{Deep MLP} - 61.79\%
    \begin{itemize}
        \item 4 layers, 63K params
    \end{itemize}
    \item \textbf{Residual Net} - 61.62\%
    \begin{itemize}
        \item Skip connections, 418K params
    \end{itemize}
    \item \textbf{Simple MLP} - 61.61\%
    \item \textbf{Wide \& Deep} - 61.52\%
    \item \textbf{Attention Net} - 61.45\%
    \begin{itemize}
        \item Multi-head, 1.6M params
    \end{itemize}
    \item \textbf{FT-Transformer} - 61.45\%
    \begin{itemize}
        \item BERT-style, only 38K params!
    \end{itemize}
\end{enumerate}

\column{0.5\textwidth}
\textbf{Critical Learnings:}
\begin{itemize}
    \item \textbf{PyTorch} from scratch
    \item \textbf{GPU:} Apple M4 MPS
    \item \textbf{All DL models: ~61.5\%}
    \begin{itemize}
        \item Architecture matters less
        \item Dataset-limited
    \end{itemize}
    \item \textbf{Best Hyperparameters:}
    \begin{itemize}
        \item Batch: 512, Dropout: 0.3
        \item LR: 0.001 + scheduling
        \item Early stopping essential
    \end{itemize}
\end{itemize}

\begin{alertblock}{Big Learning}
\textbf{ML $>$ DL for tabular by 1.15\%}\\
Confirmed research: Tree ensembles beat neural nets on structured data
\end{alertblock}
\end{columns}
\end{frame}

\begin{frame}{Best DL Model: Deep MLP Performance}
\begin{columns}[T]
\column{0.5\textwidth}
\textbf{Architecture:}
\begin{itemize}
    \item \textbf{Type:} Deep Multi-Layer Perceptron
    \item \textbf{Layers:} 4 hidden layers
    \begin{itemize}
        \item 256 $\rightarrow$ 128 $\rightarrow$ 64 $\rightarrow$ 32
    \end{itemize}
    \item \textbf{Parameters:} 63,714
    \item \textbf{Regularization:}
    \begin{itemize}
        \item BatchNorm after each layer
        \item Dropout: 0.3
    \end{itemize}
    \item \textbf{Optimizer:} Adam
    \item \textbf{Learning Rate:} 0.001
\end{itemize}

\column{0.5\textwidth}
\textbf{Performance Metrics:}
\begin{itemize}
    \item \textbf{Accuracy:} 61.79\%
    \item \textbf{F1 Score:} 0.6130
    \item \textbf{Best Val Loss:} 0.6623
    \item \textbf{Training Time:} ~8 minutes
\end{itemize}

\vspace{0.3cm}

\textbf{Key Insights:}
\begin{itemize}
    \item Best among 6 DL architectures
    \item 1.15\% below LightGBM
    \item Architecture depth matters
    \item Regularization essential
    \item Tree ensembles still superior for tabular data
\end{itemize}
\end{columns}
\end{frame}

% Section 4: Implementation & Deployment
\section{Implementation \& Deployment}

\subsection{System Architecture}
\begin{frame}{Full-Stack Implementation \& Deployment}
\begin{columns}[T]
\column{0.5\textwidth}
\textbf{Technology Stack:}
\begin{itemize}
    \item \textbf{ML:} scikit-learn, LightGBM
    \item \textbf{DL:} PyTorch 2.9.1, Apple MPS
    \item \textbf{Web:} Next.js 14 + React
    \item \textbf{Deployment:} stf.milav.in
\end{itemize}

\vspace{0.3cm}

\textbf{Web Application Features:}
\begin{itemize}
    \item \textbf{Model Dashboard:} All 13 models with specs
    \item \textbf{Live Predictions:} REST API
    \item \textbf{Interactive UI:} Comparison charts
    \item \textbf{Documentation:} Complete GitHub repo
\end{itemize}

\column{0.5\textwidth}
\textbf{Production Deployment:}
\begin{itemize}
    \item Model serving with preprocessing
    \item RESTful API endpoints
    \item Responsive design
    \item Performance visualization
\end{itemize}

\vspace{0.3cm}

\begin{block}{Live Web App}
\textbf{Visit:} \url{https://stf.milav.in}
\begin{itemize}
    \item Browse all models
    \item View hyperparameters \& metrics
    \item Test live predictions
    \item Access source code
\end{itemize}
\end{block}
\end{columns}
\end{frame}

% Section 5: Conclusion
\section{Conclusion}

\subsection{Key Findings}
\begin{frame}{Key Findings \& Insights}
\begin{columns}[T]
\column{0.5\textwidth}
\textbf{Model Performance:}
\begin{itemize}
    \item \textbf{LightGBM:} 62.94\% (Best)
    \begin{itemize}
        \item F1: 0.6286, Precision: 0.6299
    \end{itemize}
    \item \textbf{Deep MLP:} 61.79\% (Best DL)
    \item \textbf{Kaggle Top:} 69.6\%
    \item \textbf{Gap:} 6.7\% indicates high irreducible error
\end{itemize}

\vspace{0.3cm}

\textbf{Technical Insights:}
\begin{itemize}
    \item ML outperforms DL for tabular data
    \item Weak correlations limit all models
    \item \textbf{FT-Transformer:} Promising - longer training gave better scores, but hardware/time limited full exploration
\end{itemize}

\column{0.5\textwidth}
\textbf{Practical Implications:}
\begin{itemize}
    \item \textbf{Real-world deployment:}
    \begin{itemize}
        \item 62.94\% accuracy
        \item Needs human oversight
        \item First-line screening
    \end{itemize}
    \item \textbf{Production app:} stf.milav.in
    \begin{itemize}
        \item Model dashboard
        \item Live predictions
        \item Complete documentation
    \end{itemize}
\end{itemize}

\vspace{0.3cm}

\textbf{Contributions:}
\begin{itemize}
    \item 13 models evaluated
    \item FT-Transformer implemented
    \item Full-stack deployment
    \item Reproducible pipeline
\end{itemize}
\end{columns}
\end{frame}

\subsection{Challenges \& Limitations}
\begin{frame}{Challenges, Limitations \& Future Work}
\begin{columns}[T]
\column{0.5\textwidth}
\begin{alertblock}{Key Limitations}
\begin{itemize}
    \item \textbf{Dataset Quality:}
    \begin{itemize}
        \item High irreducible error
        \item Weak features (max corr: 0.118)
        \item Missing critical data
    \end{itemize}
    \item \textbf{Performance Ceiling:}
    \begin{itemize}
        \item Our: 62.94\%, Top: 69.6\%
        \item 6.7\% gap from better features
    \end{itemize}
    \item \textbf{Deployment:}
    \begin{itemize}
        \item 37\% error rate
        \item Requires human oversight
    \end{itemize}
\end{itemize}
\end{alertblock}

\column{0.5\textwidth}
\textbf{Future Enhancements:}
\begin{itemize}
    \item \textcolor{green}{$\checkmark$} DL integration complete
    \item \textbf{Short-term:}
    \begin{itemize}
        \item Explainable AI (SHAP)
        \item Hybrid ML-DL ensembles
        \item Cost-sensitive learning
    \end{itemize}
    \item \textbf{Long-term:}
    \begin{itemize}
        \item Real-time deployment
        \item Multi-class detection
        \item Transfer learning
        \item Edge deployment
    \end{itemize}
\end{itemize}
\end{columns}
\end{frame}

\begin{frame}{Resources}
\begin{block}{Project Resources}
\textbf{Kaggle Competition \& Data:}\\
\url{https://www.kaggle.com/competitions/System-Threat-Forecaster/}

\vspace{0.3cm}

\textbf{Git Repository:}\\
\url{https://github.com/milavdabgar/qip-project-stf}

\vspace{0.3cm}

\textbf{Next.js Web App:}\\
\url{https://stf.milav.in}
\end{block}
\end{frame}

% Thank You Slide
\begin{frame}
\begin{center}
{\Huge Thank You!}

\vspace{1cm}

{\Large Questions?}

\vspace{1cm}

\textbf{Milav Jayeshkumar Dabgar}\\
Government Polytechnic Palanpur\\
Department of Electronics and Communication Engineering

\end{center}
\end{frame}

\end{document}
