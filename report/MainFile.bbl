% Generated by IEEEtran.bst, version: 1.13 (2008/09/30)
\begin{thebibliography}{1}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{shwartz2022tabular}
R.~Shwartz-Ziv and A.~Armon, ``Tabular data: Deep learning is not all you
  need,'' \emph{Information Fusion}, vol.~81, pp. 84--90, 2022.

\bibitem{grinsztajn2022tree}
L.~Grinsztajn, E.~Oyallon, and G.~Varoquaux, ``Why do tree-based models still
  outperform deep learning on typical tabular data?'' \emph{Advances in Neural
  Information Processing Systems}, vol.~35, pp. 507--520, 2022.

\bibitem{kaggle_stf_competition}
\BIBentryALTinterwordspacing
{Kaggle}, ``System threat forecaster - kaggle competition,'' 2025, accessed:
  December 2025. [Online]. Available:
  \url{https://www.kaggle.com/competitions/System-Threat-Forecaster/}
\BIBentrySTDinterwordspacing

\bibitem{ke2017lightgbm}
G.~Ke, Q.~Meng, T.~Finley, T.~Wang, W.~Chen, W.~Ma, Q.~Ye, and T.-Y. Liu,
  ``Lightgbm: A highly efficient gradient boosting decision tree,''
  \emph{Advances in Neural Information Processing Systems}, vol.~30, pp.
  3146--3154, 2017.

\end{thebibliography}
